{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1572</td>\n",
       "      <td>bomb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The bomb was so appropriate ?? seen as my fami...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10546</td>\n",
       "      <td>windstorm</td>\n",
       "      <td>Georgia ? Tennessee</td>\n",
       "      <td>When I breathe it sounds like a windstorm. Hah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10647</td>\n",
       "      <td>wounds</td>\n",
       "      <td>Kashmir!</td>\n",
       "      <td>Acc to the study conducted by SKIMS morethan 5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5886</td>\n",
       "      <td>harm</td>\n",
       "      <td>Massachusetts, USA</td>\n",
       "      <td>@tareksocal I think a lot of celebrities have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5284</td>\n",
       "      <td>fear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I want to be with you forever\\nStay by my side...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6801</td>\n",
       "      <td>loud%20bang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#ActionMoviesTaughtUs things actually can expl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3136</td>\n",
       "      <td>debris</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>Experts leave lab as Malaysia confirms debris ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8817</td>\n",
       "      <td>sirens</td>\n",
       "      <td>miami x dallas</td>\n",
       "      <td>Lets Goooooooo http://t.co/fZ5eW4iHmB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2643</td>\n",
       "      <td>crashed</td>\n",
       "      <td>Kingswinford</td>\n",
       "      <td>I just nearly crashed my car typing 'Paul Rudd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7580</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>Families to sue over Legionnaires: More than 4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9208</td>\n",
       "      <td>suicide%20bombing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@JewhadiTM It is almost amazing to think someo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5178</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Injuries Illnesses and Fatalities Latest Numbe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9907</td>\n",
       "      <td>traumatised</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@brookesddl I am traumatised the lil shit near...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3256</td>\n",
       "      <td>demolish</td>\n",
       "      <td>ÌÏT: 0.0,0.0</td>\n",
       "      <td>Enugu Government to demolish illegal structure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>476</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>East Coast</td>\n",
       "      <td>@Karnythia my niece is gaining the ability to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6085</td>\n",
       "      <td>hellfire</td>\n",
       "      <td>Rheinbach / Germany</td>\n",
       "      <td>Orchid - Sign Of The Witch http://t.co/YtkXwPyIHg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8289</td>\n",
       "      <td>rioting</td>\n",
       "      <td>A little house in the outback.</td>\n",
       "      <td>AM `bbcnews The Ass British Insurers says riot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4385</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>Desde Republica Argentina</td>\n",
       "      <td>#Sismo M 1.3 - 1km NNE of The Geysers Californ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6736</td>\n",
       "      <td>lava</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>@YoungHeroesID 4. Lava Blast Power Red #Panthe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8473</td>\n",
       "      <td>screamed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not because i want to cheat or anything. Just ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>898</td>\n",
       "      <td>bioterrorism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To fight bioterrorism sir.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9212</td>\n",
       "      <td>suicide%20bombing</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>INFOGRAPHIC: At least 20 Turkish security offi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1319</td>\n",
       "      <td>bloody</td>\n",
       "      <td>PH</td>\n",
       "      <td>Friday supposed to be a happy day but it's a b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9597</td>\n",
       "      <td>thunder</td>\n",
       "      <td>Accra,Ghana</td>\n",
       "      <td>Please please u gotta listen to @leonalewis # ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7295</td>\n",
       "      <td>nuclear%20reactor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Err:509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4395</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Sure the #Megaquake story brought a sense of p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1525</td>\n",
       "      <td>body%20bags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zicac Vintage Leather Briefcase Messenger Satc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5675</td>\n",
       "      <td>floods</td>\n",
       "      <td>California</td>\n",
       "      <td>Floods Fishing Finally Sunshine &amp;amp; Fab Deal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7169</td>\n",
       "      <td>mudslide</td>\n",
       "      <td>the burrow</td>\n",
       "      <td>DORETTE THATS THE NAME OF THE MUDSLIDE CAKE MAKER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5238</td>\n",
       "      <td>fatality</td>\n",
       "      <td>Utica NY</td>\n",
       "      <td>08/3/15: CAT FATALITY: UTICA NY; PLEASANT &amp;amp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>4608</td>\n",
       "      <td>emergency%20services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're #hiring! Click to apply: RN II/EMERGENCY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>4442</td>\n",
       "      <td>electrocute</td>\n",
       "      <td>Cairo, Egypt.</td>\n",
       "      <td>But the sea would..electrocute us all.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>9657</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#usNWSgov Severe Weather Statement issued Augu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>1362</td>\n",
       "      <td>blown%20up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guaranteed been bitten by some mutant mosquito...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>3114</td>\n",
       "      <td>debris</td>\n",
       "      <td>46.950109,7.439469</td>\n",
       "      <td>How Missing JetÛªs Debris Could Have Floated ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7588</th>\n",
       "      <td>3006</td>\n",
       "      <td>death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my vibrator shaped vape done busted</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>1090</td>\n",
       "      <td>blew%20up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I think I just blew up @HopeInHearts notificat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>3982</td>\n",
       "      <td>devastation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70 Years After Atomic Bombs Japan Still Strugg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>5465</td>\n",
       "      <td>flames</td>\n",
       "      <td>New York</td>\n",
       "      <td>*NEW* Snap On Tools Black baseball Hat/Cap Sil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>5905</td>\n",
       "      <td>harm</td>\n",
       "      <td>WORLD WIDE</td>\n",
       "      <td>ÛÏFor I know the plans I have for youÛ decl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>752</td>\n",
       "      <td>avalanche</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Colorado #Avalanche Men's Official Colorado A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>2945</td>\n",
       "      <td>danger</td>\n",
       "      <td>Israel</td>\n",
       "      <td>In my experience if you're always angry and cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>8298</td>\n",
       "      <td>rubble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My parents are so impulsive sometimes. I remem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>10730</td>\n",
       "      <td>wreck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@TitorTau The Loretta Lynch one was fuckin' HI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>2255</td>\n",
       "      <td>cliff%20fall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@D33munni @JeanNamibian noooooooo ... *proceed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>5982</td>\n",
       "      <td>hazard</td>\n",
       "      <td>ilford</td>\n",
       "      <td>Fair enough we have two of the best attacking ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>9007</td>\n",
       "      <td>stretcher</td>\n",
       "      <td>hatena bookmark</td>\n",
       "      <td>*New!* Stretcher in 5 min https://t.co/q5MDsNb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>6793</td>\n",
       "      <td>lightning</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>Lightning strike in the distance via /r/pics h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>3521</td>\n",
       "      <td>derailment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@greateranglia I know the cow incident not yr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7602</th>\n",
       "      <td>4204</td>\n",
       "      <td>drowned</td>\n",
       "      <td>Alberta, VA</td>\n",
       "      <td>http://t.co/MoA0q0AuFa Jacksonville family ban...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>9940</td>\n",
       "      <td>trouble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@cspan #Prez. Mr. President you are the bigges...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>9341</td>\n",
       "      <td>survive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suicide of a Superpower : Will America Survive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>5919</td>\n",
       "      <td>harm</td>\n",
       "      <td>10-Jul</td>\n",
       "      <td>@wowsavannah what's the harm?? they're collect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>2141</td>\n",
       "      <td>catastrophe</td>\n",
       "      <td>Azeroth</td>\n",
       "      <td>Chances are many of us are still digging out f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>8068</td>\n",
       "      <td>rescue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coastal German Shepherd Rescue OC shared a lin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>9287</td>\n",
       "      <td>sunk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@silverstar58200 I felt bad for Romero. He car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>4405</td>\n",
       "      <td>electrocute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when you got an extension cord that extends fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>3721</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian customs destroyed a total of 319 tons ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>5954</td>\n",
       "      <td>hazard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Eden Hazard of Hockey https://t.co/RbbnjkoqUD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>64</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I wanted to set Chicago ablaze with my preachi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id               keyword                        location  \\\n",
       "0      1572                  bomb                             NaN   \n",
       "1     10546             windstorm             Georgia ? Tennessee   \n",
       "2     10647                wounds                        Kashmir!   \n",
       "3      5886                  harm              Massachusetts, USA   \n",
       "4      5284                  fear                             NaN   \n",
       "5      6801           loud%20bang                             NaN   \n",
       "6      3136                debris                 Berlin, Germany   \n",
       "7      8817                sirens                 miami x dallas    \n",
       "8      2643               crashed                    Kingswinford   \n",
       "9      7580              outbreak                        Anywhere   \n",
       "10     9208     suicide%20bombing                             NaN   \n",
       "11     5178            fatalities                             NaN   \n",
       "12     9907           traumatised                             NaN   \n",
       "13     3256              demolish                    ÌÏT: 0.0,0.0   \n",
       "14      476            armageddon                      East Coast   \n",
       "15     6085              hellfire             Rheinbach / Germany   \n",
       "16     8289               rioting  A little house in the outback.   \n",
       "17     4385            earthquake       Desde Republica Argentina   \n",
       "18     6736                  lava                       Indonesia   \n",
       "19     8473              screamed                             NaN   \n",
       "20      898          bioterrorism                             NaN   \n",
       "21     9212     suicide%20bombing                        Istanbul   \n",
       "22     1319                bloody                              PH   \n",
       "23     9597               thunder                     Accra,Ghana   \n",
       "24     7295     nuclear%20reactor                             NaN   \n",
       "25     4395            earthquake                     Seattle, WA   \n",
       "26     1525           body%20bags                             NaN   \n",
       "27     5675                floods                      California   \n",
       "28     7169              mudslide                      the burrow   \n",
       "29     5238              fatality                        Utica NY   \n",
       "...     ...                   ...                             ...   \n",
       "7583   4608  emergency%20services                             NaN   \n",
       "7584   4442           electrocute                   Cairo, Egypt.   \n",
       "7585   9657          thunderstorm                             NaN   \n",
       "7586   1362            blown%20up                             NaN   \n",
       "7587   3114                debris              46.950109,7.439469   \n",
       "7588   3006                 death                             NaN   \n",
       "7589   1090             blew%20up                             NaN   \n",
       "7590   3982           devastation                             NaN   \n",
       "7591   5465                flames                        New York   \n",
       "7592   5905                  harm                      WORLD WIDE   \n",
       "7593    752             avalanche                             NaN   \n",
       "7594   2945                danger                          Israel   \n",
       "7595   8298                rubble                             NaN   \n",
       "7596  10730                 wreck                             NaN   \n",
       "7597   2255          cliff%20fall                             NaN   \n",
       "7598   5982                hazard                          ilford   \n",
       "7599   9007             stretcher                 hatena bookmark   \n",
       "7600   6793             lightning                         Reddit    \n",
       "7601   3521            derailment                             NaN   \n",
       "7602   4204               drowned                     Alberta, VA   \n",
       "7603   9940               trouble                             NaN   \n",
       "7604   9341               survive                             NaN   \n",
       "7605   5919                  harm                          10-Jul   \n",
       "7606   2141           catastrophe                         Azeroth   \n",
       "7607   8068                rescue                             NaN   \n",
       "7608   9287                  sunk                             NaN   \n",
       "7609   4405           electrocute                             NaN   \n",
       "7610   3721             destroyed                             NaN   \n",
       "7611   5954                hazard                             NaN   \n",
       "7612     64                ablaze                             NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     The bomb was so appropriate ?? seen as my fami...       0  \n",
       "1     When I breathe it sounds like a windstorm. Hah...       0  \n",
       "2     Acc to the study conducted by SKIMS morethan 5...       1  \n",
       "3     @tareksocal I think a lot of celebrities have ...       0  \n",
       "4     I want to be with you forever\\nStay by my side...       0  \n",
       "5     #ActionMoviesTaughtUs things actually can expl...       0  \n",
       "6     Experts leave lab as Malaysia confirms debris ...       1  \n",
       "7                 Lets Goooooooo http://t.co/fZ5eW4iHmB       0  \n",
       "8     I just nearly crashed my car typing 'Paul Rudd...       0  \n",
       "9     Families to sue over Legionnaires: More than 4...       1  \n",
       "10    @JewhadiTM It is almost amazing to think someo...       1  \n",
       "11    Injuries Illnesses and Fatalities Latest Numbe...       1  \n",
       "12    @brookesddl I am traumatised the lil shit near...       0  \n",
       "13    Enugu Government to demolish illegal structure...       0  \n",
       "14    @Karnythia my niece is gaining the ability to ...       0  \n",
       "15    Orchid - Sign Of The Witch http://t.co/YtkXwPyIHg       0  \n",
       "16    AM `bbcnews The Ass British Insurers says riot...       1  \n",
       "17    #Sismo M 1.3 - 1km NNE of The Geysers Californ...       0  \n",
       "18    @YoungHeroesID 4. Lava Blast Power Red #Panthe...       0  \n",
       "19    Not because i want to cheat or anything. Just ...       0  \n",
       "20                           To fight bioterrorism sir.       0  \n",
       "21    INFOGRAPHIC: At least 20 Turkish security offi...       1  \n",
       "22    Friday supposed to be a happy day but it's a b...       0  \n",
       "23    Please please u gotta listen to @leonalewis # ...       0  \n",
       "24                                              Err:509       0  \n",
       "25    Sure the #Megaquake story brought a sense of p...       1  \n",
       "26    Zicac Vintage Leather Briefcase Messenger Satc...       0  \n",
       "27    Floods Fishing Finally Sunshine &amp; Fab Deal...       0  \n",
       "28    DORETTE THATS THE NAME OF THE MUDSLIDE CAKE MAKER       0  \n",
       "29    08/3/15: CAT FATALITY: UTICA NY; PLEASANT &amp...       0  \n",
       "...                                                 ...     ...  \n",
       "7583  We're #hiring! Click to apply: RN II/EMERGENCY...       1  \n",
       "7584             But the sea would..electrocute us all.       0  \n",
       "7585  #usNWSgov Severe Weather Statement issued Augu...       1  \n",
       "7586  Guaranteed been bitten by some mutant mosquito...       0  \n",
       "7587  How Missing JetÛªs Debris Could Have Floated ...       1  \n",
       "7588                my vibrator shaped vape done busted       0  \n",
       "7589  I think I just blew up @HopeInHearts notificat...       0  \n",
       "7590  70 Years After Atomic Bombs Japan Still Strugg...       1  \n",
       "7591  *NEW* Snap On Tools Black baseball Hat/Cap Sil...       0  \n",
       "7592  ÛÏFor I know the plans I have for youÛ decl...       0  \n",
       "7593  #Colorado #Avalanche Men's Official Colorado A...       0  \n",
       "7594  In my experience if you're always angry and cr...       0  \n",
       "7595  My parents are so impulsive sometimes. I remem...       0  \n",
       "7596  @TitorTau The Loretta Lynch one was fuckin' HI...       0  \n",
       "7597  @D33munni @JeanNamibian noooooooo ... *proceed...       0  \n",
       "7598  Fair enough we have two of the best attacking ...       0  \n",
       "7599  *New!* Stretcher in 5 min https://t.co/q5MDsNb...       0  \n",
       "7600  Lightning strike in the distance via /r/pics h...       1  \n",
       "7601  @greateranglia I know the cow incident not yr ...       1  \n",
       "7602  http://t.co/MoA0q0AuFa Jacksonville family ban...       0  \n",
       "7603  @cspan #Prez. Mr. President you are the bigges...       1  \n",
       "7604  Suicide of a Superpower : Will America Survive...       0  \n",
       "7605  @wowsavannah what's the harm?? they're collect...       0  \n",
       "7606  Chances are many of us are still digging out f...       1  \n",
       "7607  Coastal German Shepherd Rescue OC shared a lin...       0  \n",
       "7608  @silverstar58200 I felt bad for Romero. He car...       0  \n",
       "7609  when you got an extension cord that extends fr...       0  \n",
       "7610  Russian customs destroyed a total of 319 tons ...       0  \n",
       "7611  The Eden Hazard of Hockey https://t.co/RbbnjkoqUD       0  \n",
       "7612  I wanted to set Chicago ablaze with my preachi...       0  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_dataset = pd.read_csv('train.csv')\n",
    "train_dataset = train_dataset.sample(frac=1).reset_index(drop=True)\n",
    "predict_dataset = pd.read_csv('test.csv')\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          7613\n",
       "keyword     7552\n",
       "location    5080\n",
       "text        7613\n",
       "target      7613\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.count()\n",
    "#The dataset (train and test) has 10876 lines, 7613 have the variable \"target\" (train) and 3263 are test data\n",
    "#The variable keyword gives the theme of the tweet, it allows to categorize tweets, it is missing in some instances\n",
    "#Text is the tweet, they are all in English, they contain many special characters that need to be removed\n",
    "#Location is missing on a majority of instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment of the \"text\" variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting hashtags\n",
    "import re\n",
    "def extract_hashtags(dataset):\n",
    "    hashtags = dataset['text'].str.extractall(r'#([A-Za-z0-9]+)')\n",
    "    hashtags.index = hashtags.index.get_level_values(0)\n",
    "    hashtags = hashtags.groupby([hashtags.index]).agg(lambda col: list(col))\n",
    "    hashtags = hashtags.rename(columns={0:'hashtags'})\n",
    "    dataset = dataset.merge(hashtags, how='left', left_index=True, right_index=True)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = extract_hashtags(train_dataset)\n",
    "predict_dataset = extract_hashtags(predict_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub('http[\\S]+', '', string)\n",
    "    string = re.sub('[^\\w\\s]','', string)\n",
    "    string = re.sub('[0-9]+', '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['text'] = train_dataset['text'].apply(lambda string : normalize_text(string))\n",
    "predict_dataset['text'] = predict_dataset['text'].apply(lambda string : normalize_text(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf vectorization and simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy tokenization + Lemmatization + removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "def tokenize(string):\n",
    "    tokens = nlp(string)\n",
    "    tokens_nostop = ''\n",
    "    for token in tokens:\n",
    "        if token.text not in stop_words:\n",
    "            tokens_nostop = tokens_nostop + ' ' + token.lemma_\n",
    "    return tokens_nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['text'] = train_dataset['text'].apply(lambda text: tokenize(text))\n",
    "predict_dataset['text'] = predict_dataset['text'].apply(lambda text: tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfIdf Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=2)\n",
    "tfidf_vectorizer.fit(train_dataset['text'])\n",
    "\n",
    "train_dataset_X = tfidf_vectorizer.transform(train_dataset['text']).toarray()\n",
    "predict_dataset_X = tfidf_vectorizer.transform(predict_dataset['text']).toarray()\n",
    "\n",
    "#y\n",
    "train_dataset_y = np.array(train_dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataset_X, train_dataset_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Model: simple logistic regression on tfidf features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_predicted = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 79.62594508555512%\n"
     ]
    }
   ],
   "source": [
    "#Performance metrics\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_predicted)\n",
    "print('Accuracy is: '+ str(100*accuracy)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1295,  127],\n",
       "       [ 385,  706]], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset_predict_y = classifier.predict(predict_dataset_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame(predict_dataset_predict_y, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = prediction_df.merge(predict_dataset[['id']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = prediction_df[['id','target']]\n",
    "prediction_df.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 2)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This submission got a result of 79.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'opt_einsum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-47741b6ba1f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfdev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# Ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandard_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# Namespaces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\standard_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial_math_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;31m# TODO(vrv): Switch to import * once we're okay with exposing the module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mopt_einsum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'opt_einsum'"
     ]
    }
   ],
   "source": [
    "#Neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(300, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "\n",
    "model_nn.add(Dense(300, activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "\n",
    "model_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_nn.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5100/5100 [==============================] - 7s 1ms/step - loss: 19.6711 - accuracy: 0.4457\n",
      "Epoch 2/500\n",
      "5100/5100 [==============================] - 4s 791us/step - loss: 18.0249 - accuracy: 0.5167\n",
      "Epoch 3/500\n",
      "5100/5100 [==============================] - 4s 818us/step - loss: 16.4586 - accuracy: 0.5678\n",
      "Epoch 4/500\n",
      "5100/5100 [==============================] - 4s 813us/step - loss: 14.9721 - accuracy: 0.5722\n",
      "Epoch 5/500\n",
      "5100/5100 [==============================] - 4s 825us/step - loss: 13.5657 - accuracy: 0.5725 2s - loss: 13.9 - ETA: 1s - loss: 13.75\n",
      "Epoch 6/500\n",
      "5100/5100 [==============================] - 4s 843us/step - loss: 12.2397 - accuracy: 0.5725\n",
      "Epoch 7/500\n",
      "5100/5100 [==============================] - 4s 832us/step - loss: 10.9942 - accuracy: 0.5725 1\n",
      "Epoch 8/500\n",
      "5100/5100 [==============================] - 4s 841us/step - loss: 9.8291 - accuracy: 0.5725\n",
      "Epoch 9/500\n",
      "5100/5100 [==============================] - 4s 866us/step - loss: 8.7448 - accuracy: 0.5725\n",
      "Epoch 10/500\n",
      "5100/5100 [==============================] - 4s 847us/step - loss: 7.7417 - accuracy: 0.5725\n",
      "Epoch 11/500\n",
      "5100/5100 [==============================] - 4s 840us/step - loss: 6.8190 - accuracy: 0.5725\n",
      "Epoch 12/500\n",
      "5100/5100 [==============================] - 5s 884us/step - loss: 5.9768 - accuracy: 0.5725\n",
      "Epoch 13/500\n",
      "5100/5100 [==============================] - 4s 861us/step - loss: 5.2149 - accuracy: 0.5725\n",
      "Epoch 14/500\n",
      "5100/5100 [==============================] - 4s 839us/step - loss: 4.5332 - accuracy: 0.5725\n",
      "Epoch 15/500\n",
      "5100/5100 [==============================] - 4s 836us/step - loss: 3.9327 - accuracy: 0.5725\n",
      "Epoch 16/500\n",
      "5100/5100 [==============================] - 5s 887us/step - loss: 3.4127 - accuracy: 0.5725\n",
      "Epoch 17/500\n",
      "5100/5100 [==============================] - 5s 942us/step - loss: 2.9731 - accuracy: 0.5725\n",
      "Epoch 18/500\n",
      "5100/5100 [==============================] - 4s 856us/step - loss: 2.6142 - accuracy: 0.57250s - loss: 2.6281 - ac\n",
      "Epoch 19/500\n",
      "5100/5100 [==============================] - 4s 845us/step - loss: 2.3361 - accuracy: 0.5725\n",
      "Epoch 20/500\n",
      "5100/5100 [==============================] - 4s 848us/step - loss: 2.1384 - accuracy: 0.5725\n",
      "Epoch 21/500\n",
      "5100/5100 [==============================] - 4s 827us/step - loss: 2.0211 - accuracy: 0.5725\n",
      "Epoch 22/500\n",
      "5100/5100 [==============================] - 4s 837us/step - loss: 1.9653 - accuracy: 0.5725\n",
      "Epoch 23/500\n",
      "5100/5100 [==============================] - 4s 836us/step - loss: 1.9193 - accuracy: 0.5725\n",
      "Epoch 24/500\n",
      "5100/5100 [==============================] - 4s 835us/step - loss: 1.8742 - accuracy: 0.5725\n",
      "Epoch 25/500\n",
      "5100/5100 [==============================] - 4s 833us/step - loss: 1.8299 - accuracy: 0.5725\n",
      "Epoch 26/500\n",
      "5100/5100 [==============================] - 4s 827us/step - loss: 1.7864 - accuracy: 0.5725\n",
      "Epoch 27/500\n",
      "5100/5100 [==============================] - 4s 835us/step - loss: 1.7438 - accuracy: 0.5725\n",
      "Epoch 28/500\n",
      "5100/5100 [==============================] - 4s 832us/step - loss: 1.7020 - accuracy: 0.5725\n",
      "Epoch 29/500\n",
      "5100/5100 [==============================] - 4s 821us/step - loss: 1.6611 - accuracy: 0.5725\n",
      "Epoch 30/500\n",
      "5100/5100 [==============================] - 4s 820us/step - loss: 1.6210 - accuracy: 0.5725\n",
      "Epoch 31/500\n",
      "5100/5100 [==============================] - 4s 828us/step - loss: 1.5817 - accuracy: 0.5725\n",
      "Epoch 32/500\n",
      "5100/5100 [==============================] - 4s 849us/step - loss: 1.5433 - accuracy: 0.5725\n",
      "Epoch 33/500\n",
      "5100/5100 [==============================] - 4s 882us/step - loss: 1.5057 - accuracy: 0.5725\n",
      "Epoch 34/500\n",
      "5100/5100 [==============================] - 4s 830us/step - loss: 1.4689 - accuracy: 0.5725\n",
      "Epoch 35/500\n",
      "5100/5100 [==============================] - 4s 833us/step - loss: 1.4329 - accuracy: 0.5725\n",
      "Epoch 36/500\n",
      "5100/5100 [==============================] - 4s 820us/step - loss: 1.3978 - accuracy: 0.5725\n",
      "Epoch 37/500\n",
      "5100/5100 [==============================] - 4s 830us/step - loss: 1.3635 - accuracy: 0.5725\n",
      "Epoch 38/500\n",
      "5100/5100 [==============================] - 5s 924us/step - loss: 1.3299 - accuracy: 0.5725\n",
      "Epoch 39/500\n",
      "5100/5100 [==============================] - 4s 801us/step - loss: 1.2973 - accuracy: 0.5725\n",
      "Epoch 40/500\n",
      "5100/5100 [==============================] - 5s 1ms/step - loss: 1.2655 - accuracy: 0.5725\n",
      "Epoch 41/500\n",
      "5100/5100 [==============================] - 4s 826us/step - loss: 1.2345 - accuracy: 0.5725\n",
      "Epoch 42/500\n",
      "5100/5100 [==============================] - 5s 948us/step - loss: 1.2043 - accuracy: 0.5725\n",
      "Epoch 43/500\n",
      "5100/5100 [==============================] - 5s 963us/step - loss: 1.1750 - accuracy: 0.5725\n",
      "Epoch 44/500\n",
      "5100/5100 [==============================] - 4s 753us/step - loss: 1.1465 - accuracy: 0.5725\n",
      "Epoch 45/500\n",
      "5100/5100 [==============================] - 4s 761us/step - loss: 1.1189 - accuracy: 0.5725\n",
      "Epoch 46/500\n",
      "5100/5100 [==============================] - 4s 811us/step - loss: 1.0921 - accuracy: 0.5725\n",
      "Epoch 47/500\n",
      "5100/5100 [==============================] - 4s 838us/step - loss: 1.0662 - accuracy: 0.5725\n",
      "Epoch 48/500\n",
      "5100/5100 [==============================] - 4s 816us/step - loss: 1.0411 - accuracy: 0.5725\n",
      "Epoch 49/500\n",
      "5100/5100 [==============================] - 4s 812us/step - loss: 1.0169 - accuracy: 0.5725\n",
      "Epoch 50/500\n",
      "5100/5100 [==============================] - 4s 791us/step - loss: 0.9935 - accuracy: 0.5725\n",
      "Epoch 51/500\n",
      "5100/5100 [==============================] - 4s 826us/step - loss: 0.9710 - accuracy: 0.5725\n",
      "Epoch 52/500\n",
      "5100/5100 [==============================] - 4s 806us/step - loss: 0.9493 - accuracy: 0.5725\n",
      "Epoch 53/500\n",
      "5100/5100 [==============================] - 5s 1ms/step - loss: 0.9285 - accuracy: 0.5725\n",
      "Epoch 54/500\n",
      "5100/5100 [==============================] - 5s 912us/step - loss: 0.9086 - accuracy: 0.5725\n",
      "Epoch 55/500\n",
      "5100/5100 [==============================] - 5s 899us/step - loss: 0.8895 - accuracy: 0.5725\n",
      "Epoch 56/500\n",
      "5100/5100 [==============================] - 5s 1ms/step - loss: 0.8712 - accuracy: 0.5725: 1s -\n",
      "Epoch 57/500\n",
      "5100/5100 [==============================] - 5s 983us/step - loss: 0.8538 - accuracy: 0.5725\n",
      "Epoch 58/500\n",
      "5100/5100 [==============================] - 4s 870us/step - loss: 0.8372 - accuracy: 0.5725\n",
      "Epoch 59/500\n",
      "5100/5100 [==============================] - 5s 932us/step - loss: 0.8215 - accuracy: 0.5725\n",
      "Epoch 60/500\n",
      "5100/5100 [==============================] - 5s 889us/step - loss: 0.8067 - accuracy: 0.5725\n",
      "Epoch 61/500\n",
      "5100/5100 [==============================] - 4s 873us/step - loss: 0.7927 - accuracy: 0.5725\n",
      "Epoch 62/500\n",
      "5100/5100 [==============================] - 5s 1ms/step - loss: 0.7796 - accuracy: 0.5725\n",
      "Epoch 63/500\n",
      "5100/5100 [==============================] - 4s 823us/step - loss: 0.7674 - accuracy: 0.5725\n",
      "Epoch 64/500\n",
      "5100/5100 [==============================] - 4s 805us/step - loss: 0.7560 - accuracy: 0.5725\n",
      "Epoch 65/500\n",
      "5100/5100 [==============================] - 4s 869us/step - loss: 0.7455 - accuracy: 0.5725\n",
      "Epoch 66/500\n",
      "5100/5100 [==============================] - 4s 846us/step - loss: 0.7358 - accuracy: 0.5725\n",
      "Epoch 67/500\n",
      "5100/5100 [==============================] - 4s 802us/step - loss: 0.7269 - accuracy: 0.5725\n",
      "Epoch 68/500\n",
      "5100/5100 [==============================] - 4s 881us/step - loss: 0.7189 - accuracy: 0.5725\n",
      "Epoch 69/500\n",
      "5100/5100 [==============================] - 5s 919us/step - loss: 0.7117 - accuracy: 0.5725\n",
      "Epoch 70/500\n",
      "5100/5100 [==============================] - 4s 871us/step - loss: 0.7054 - accuracy: 0.57250s - l\n",
      "Epoch 71/500\n",
      "5100/5100 [==============================] - 4s 860us/step - loss: 0.6998 - accuracy: 0.5725\n",
      "Epoch 72/500\n",
      "5100/5100 [==============================] - 4s 865us/step - loss: 0.6951 - accuracy: 0.5725\n",
      "Epoch 73/500\n",
      "5100/5100 [==============================] - 4s 864us/step - loss: 0.6913 - accuracy: 0.5725\n",
      "Epoch 74/500\n",
      "5100/5100 [==============================] - 4s 858us/step - loss: 0.6882 - accuracy: 0.5725\n",
      "Epoch 75/500\n",
      "5100/5100 [==============================] - 4s 866us/step - loss: 0.6859 - accuracy: 0.5725\n",
      "Epoch 76/500\n",
      "5100/5100 [==============================] - 4s 869us/step - loss: 0.6845 - accuracy: 0.5725\n",
      "Epoch 77/500\n",
      "5100/5100 [==============================] - 4s 867us/step - loss: 0.6839 - accuracy: 0.5725\n",
      "Epoch 78/500\n",
      "5100/5100 [==============================] - 4s 827us/step - loss: 0.6839 - accuracy: 0.5725\n",
      "Epoch 79/500\n",
      "5100/5100 [==============================] - 4s 817us/step - loss: 0.6838 - accuracy: 0.5725\n",
      "Epoch 80/500\n",
      "5100/5100 [==============================] - 4s 827us/step - loss: 0.6838 - accuracy: 0.5725\n",
      "Epoch 81/500\n",
      "5100/5100 [==============================] - 4s 818us/step - loss: 0.6838 - accuracy: 0.5725\n",
      "Epoch 82/500\n",
      "5100/5100 [==============================] - 4s 832us/step - loss: 0.6838 - accuracy: 0.5725\n",
      "Epoch 83/500\n",
      "5100/5100 [==============================] - 4s 838us/step - loss: 0.6838 - accuracy: 0.5725\n",
      "Epoch 84/500\n",
      "5100/5100 [==============================] - 4s 842us/step - loss: 0.6838 - accuracy: 0.5725\n",
      "Epoch 85/500\n",
      "2592/5100 [==============>...............] - ETA: 2s - loss: 0.6827 - accuracy: 0.5764"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-858544c58241>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtraining_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "training_process = model_nn.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(training_process.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(training_process.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = model_nn.predict(X_test)\n",
    "y_test_predicted = np.where(y_test_predicted >= 0.5, 1, y_test_predicted)\n",
    "y_test_predicted = np.where(y_test_predicted < 0.5, 0, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 56.585754078790295%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_predicted)\n",
    "print('Accuracy is: '+ str(100*accuracy)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17241 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Fit keras tokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 10000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 40\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n",
    "tokenizer.fit_on_texts(train_dataset['text'].values)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (7613, 40)\n"
     ]
    }
   ],
   "source": [
    "#X variable\n",
    "X_train_dataset = tokenizer.texts_to_sequences(train_dataset['text'].values)\n",
    "X_predict_dataset = tokenizer.texts_to_sequences(predict_dataset['text'].values)\n",
    "\n",
    "#The longest tweet has 31 tokens\n",
    "X_train_dataset = pad_sequences(X_train_dataset, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_predict_dataset = pad_sequences(X_predict_dataset, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y variable\n",
    "y_train_dataset = np.array(train_dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_dataset, y_train_dataset, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 40)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 40, 50)            500000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_28 (Spatia (None, 40, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 40)                2040      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 522,281\n",
      "Trainable params: 522,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model specification\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, SpatialDropout1D, LSTM, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train_dataset.shape[1]))\n",
    "model_rnn.add(SpatialDropout1D(0.3))\n",
    "model_rnn.add(LSTM(EMBEDDING_DIM, dropout=0.3, recurrent_dropout=0.3))\n",
    "model_rnn.add(Dense(40, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_rnn.add(Dense(1, activation='sigmoid' , kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_rnn.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5100 samples, validate on 2513 samples\n",
      "Epoch 1/100\n",
      "5100/5100 [==============================] - 4s 799us/step - loss: 1.1473 - accuracy: 0.5692 - val_loss: 1.1415 - val_accuracy: 0.5726\n",
      "Epoch 2/100\n",
      "5100/5100 [==============================] - 2s 442us/step - loss: 1.1369 - accuracy: 0.5692 - val_loss: 1.1312 - val_accuracy: 0.5726\n",
      "Epoch 3/100\n",
      "5100/5100 [==============================] - 2s 437us/step - loss: 1.1270 - accuracy: 0.5692 - val_loss: 1.1215 - val_accuracy: 0.5726\n",
      "Epoch 4/100\n",
      "5100/5100 [==============================] - 2s 441us/step - loss: 1.1175 - accuracy: 0.5692 - val_loss: 1.1123 - val_accuracy: 0.5726\n",
      "Epoch 5/100\n",
      "5100/5100 [==============================] - 3s 518us/step - loss: 1.1084 - accuracy: 0.5692 - val_loss: 1.1034 - val_accuracy: 0.5726\n",
      "Epoch 6/100\n",
      "5100/5100 [==============================] - 2s 446us/step - loss: 1.0998 - accuracy: 0.5692 - val_loss: 1.0947 - val_accuracy: 0.5726\n",
      "Epoch 7/100\n",
      "5100/5100 [==============================] - 3s 492us/step - loss: 1.0912 - accuracy: 0.5692 - val_loss: 1.0863 - val_accuracy: 0.5726\n",
      "Epoch 8/100\n",
      "5100/5100 [==============================] - 2s 468us/step - loss: 1.0827 - accuracy: 0.5692 - val_loss: 1.0780 - val_accuracy: 0.5726\n",
      "Epoch 9/100\n",
      "5100/5100 [==============================] - 3s 513us/step - loss: 1.0744 - accuracy: 0.5692 - val_loss: 1.0697 - val_accuracy: 0.5726\n",
      "Epoch 10/100\n",
      "5100/5100 [==============================] - 3s 494us/step - loss: 1.0658 - accuracy: 0.5692 - val_loss: 1.0614 - val_accuracy: 0.5726\n",
      "Epoch 11/100\n",
      "5100/5100 [==============================] - 3s 496us/step - loss: 1.0575 - accuracy: 0.5692 - val_loss: 1.0531 - val_accuracy: 0.5726\n",
      "Epoch 12/100\n",
      "5100/5100 [==============================] - 2s 469us/step - loss: 1.0493 - accuracy: 0.5692 - val_loss: 1.0447 - val_accuracy: 0.5726\n",
      "Epoch 13/100\n",
      "5100/5100 [==============================] - 2s 474us/step - loss: 1.0401 - accuracy: 0.5692 - val_loss: 1.0362 - val_accuracy: 0.5726\n",
      "Epoch 14/100\n",
      "5100/5100 [==============================] - 2s 479us/step - loss: 1.0318 - accuracy: 0.5692 - val_loss: 1.0277 - val_accuracy: 0.5726\n",
      "Epoch 15/100\n",
      "5100/5100 [==============================] - 2s 486us/step - loss: 1.0232 - accuracy: 0.5692 - val_loss: 1.0188 - val_accuracy: 0.5726\n",
      "Epoch 16/100\n",
      "5100/5100 [==============================] - 3s 504us/step - loss: 1.0122 - accuracy: 0.5692 - val_loss: 1.0085 - val_accuracy: 0.5726\n",
      "Epoch 17/100\n",
      "5100/5100 [==============================] - 2s 476us/step - loss: 1.0032 - accuracy: 0.5692 - val_loss: 0.9983 - val_accuracy: 0.5726\n",
      "Epoch 18/100\n",
      "5100/5100 [==============================] - 2s 485us/step - loss: 0.9920 - accuracy: 0.5692 - val_loss: 0.9879 - val_accuracy: 0.5726\n",
      "Epoch 19/100\n",
      "5100/5100 [==============================] - 3s 496us/step - loss: 0.9810 - accuracy: 0.5694 - val_loss: 0.9766 - val_accuracy: 0.5726\n",
      "Epoch 20/100\n",
      "5100/5100 [==============================] - 2s 480us/step - loss: 0.9684 - accuracy: 0.5745 - val_loss: 0.9643 - val_accuracy: 0.5786\n",
      "Epoch 21/100\n",
      "5100/5100 [==============================] - 3s 526us/step - loss: 0.9562 - accuracy: 0.5922 - val_loss: 0.9498 - val_accuracy: 0.6053\n",
      "Epoch 22/100\n",
      "5100/5100 [==============================] - 3s 632us/step - loss: 0.9445 - accuracy: 0.6249 - val_loss: 0.9374 - val_accuracy: 0.6319\n",
      "Epoch 23/100\n",
      "5100/5100 [==============================] - 3s 582us/step - loss: 0.9286 - accuracy: 0.6606 - val_loss: 0.9226 - val_accuracy: 0.6634\n",
      "Epoch 24/100\n",
      "5100/5100 [==============================] - 3s 516us/step - loss: 0.9132 - accuracy: 0.6992 - val_loss: 0.9092 - val_accuracy: 0.7043\n",
      "Epoch 25/100\n",
      "5100/5100 [==============================] - 3s 527us/step - loss: 0.9002 - accuracy: 0.7382 - val_loss: 0.8958 - val_accuracy: 0.7409\n",
      "Epoch 26/100\n",
      "5100/5100 [==============================] - 3s 530us/step - loss: 0.8850 - accuracy: 0.7694 - val_loss: 0.8810 - val_accuracy: 0.7509\n",
      "Epoch 27/100\n",
      "5100/5100 [==============================] - 3s 502us/step - loss: 0.8714 - accuracy: 0.7753 - val_loss: 0.8700 - val_accuracy: 0.7676\n",
      "Epoch 28/100\n",
      "5100/5100 [==============================] - 3s 549us/step - loss: 0.8578 - accuracy: 0.7988 - val_loss: 0.8585 - val_accuracy: 0.7791\n",
      "Epoch 29/100\n",
      "5100/5100 [==============================] - 3s 546us/step - loss: 0.8429 - accuracy: 0.7931 - val_loss: 0.8456 - val_accuracy: 0.7791\n",
      "Epoch 30/100\n",
      "5100/5100 [==============================] - 3s 569us/step - loss: 0.8316 - accuracy: 0.8098 - val_loss: 0.8405 - val_accuracy: 0.7923\n",
      "Epoch 31/100\n",
      "5100/5100 [==============================] - 3s 568us/step - loss: 0.8179 - accuracy: 0.8175 - val_loss: 0.8251 - val_accuracy: 0.7919\n",
      "Epoch 32/100\n",
      "5100/5100 [==============================] - 3s 535us/step - loss: 0.8071 - accuracy: 0.8218 - val_loss: 0.8187 - val_accuracy: 0.7994\n",
      "Epoch 33/100\n",
      "5100/5100 [==============================] - 3s 551us/step - loss: 0.7943 - accuracy: 0.8273 - val_loss: 0.8048 - val_accuracy: 0.7915\n",
      "Epoch 34/100\n",
      "5100/5100 [==============================] - 3s 561us/step - loss: 0.7811 - accuracy: 0.8284 - val_loss: 0.7976 - val_accuracy: 0.7982\n",
      "Epoch 35/100\n",
      "5100/5100 [==============================] - 3s 537us/step - loss: 0.7691 - accuracy: 0.8302 - val_loss: 0.7881 - val_accuracy: 0.7986\n",
      "Epoch 36/100\n",
      "5100/5100 [==============================] - 3s 551us/step - loss: 0.7573 - accuracy: 0.8353 - val_loss: 0.7823 - val_accuracy: 0.8054\n",
      "Epoch 37/100\n",
      "5100/5100 [==============================] - 3s 541us/step - loss: 0.7462 - accuracy: 0.8437 - val_loss: 0.7720 - val_accuracy: 0.8034\n",
      "Epoch 38/100\n",
      "5100/5100 [==============================] - 3s 551us/step - loss: 0.7343 - accuracy: 0.8496 - val_loss: 0.7636 - val_accuracy: 0.8042\n",
      "Epoch 39/100\n",
      "5100/5100 [==============================] - 3s 583us/step - loss: 0.7219 - accuracy: 0.8469 - val_loss: 0.7568 - val_accuracy: 0.8070\n",
      "Epoch 40/100\n",
      "5100/5100 [==============================] - 3s 549us/step - loss: 0.7099 - accuracy: 0.8527 - val_loss: 0.7479 - val_accuracy: 0.8038\n",
      "Epoch 41/100\n",
      "5100/5100 [==============================] - 3s 559us/step - loss: 0.6983 - accuracy: 0.8520 - val_loss: 0.7420 - val_accuracy: 0.8054\n",
      "Epoch 42/100\n",
      "5100/5100 [==============================] - 4s 709us/step - loss: 0.6889 - accuracy: 0.8561 - val_loss: 0.7357 - val_accuracy: 0.8050\n",
      "Epoch 43/100\n",
      "5100/5100 [==============================] - 4s 710us/step - loss: 0.6791 - accuracy: 0.8578 - val_loss: 0.7300 - val_accuracy: 0.8046\n",
      "Epoch 44/100\n",
      "5100/5100 [==============================] - 3s 615us/step - loss: 0.6683 - accuracy: 0.8702 - val_loss: 0.7229 - val_accuracy: 0.8066\n",
      "Epoch 45/100\n",
      "5100/5100 [==============================] - 3s 634us/step - loss: 0.6610 - accuracy: 0.8600 - val_loss: 0.7162 - val_accuracy: 0.8066\n",
      "Epoch 46/100\n",
      "5100/5100 [==============================] - 3s 612us/step - loss: 0.6479 - accuracy: 0.8710 - val_loss: 0.7109 - val_accuracy: 0.8058\n",
      "Epoch 47/100\n",
      "5100/5100 [==============================] - 3s 612us/step - loss: 0.6404 - accuracy: 0.8724 - val_loss: 0.7074 - val_accuracy: 0.8046\n",
      "Epoch 48/100\n",
      "5100/5100 [==============================] - 3s 645us/step - loss: 0.6253 - accuracy: 0.8806 - val_loss: 0.7004 - val_accuracy: 0.8030\n",
      "Epoch 49/100\n",
      "5100/5100 [==============================] - 3s 604us/step - loss: 0.6202 - accuracy: 0.8761 - val_loss: 0.6982 - val_accuracy: 0.8050\n",
      "Epoch 50/100\n",
      "5100/5100 [==============================] - 3s 595us/step - loss: 0.6098 - accuracy: 0.8820 - val_loss: 0.6912 - val_accuracy: 0.8058\n",
      "Epoch 51/100\n",
      "5100/5100 [==============================] - 3s 603us/step - loss: 0.5996 - accuracy: 0.8841 - val_loss: 0.6888 - val_accuracy: 0.8034\n",
      "Epoch 52/100\n",
      "5100/5100 [==============================] - 3s 564us/step - loss: 0.5926 - accuracy: 0.8822 - val_loss: 0.6844 - val_accuracy: 0.8030\n",
      "Epoch 53/100\n",
      "5100/5100 [==============================] - 3s 642us/step - loss: 0.5805 - accuracy: 0.8912 - val_loss: 0.6798 - val_accuracy: 0.8006\n",
      "Epoch 54/100\n",
      "5100/5100 [==============================] - 3s 609us/step - loss: 0.5763 - accuracy: 0.8892 - val_loss: 0.6767 - val_accuracy: 0.8038\n",
      "Epoch 55/100\n",
      "4800/5100 [===========================>..] - ETA: 0s - loss: 0.5727 - accuracy: 0.8906"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-a5f3dba20236>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    208\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                                          \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m                                          verbose=0)\n\u001b[0m\u001b[0;32m    211\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                     \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "epochs = 50\n",
    "batch_size = 300\n",
    "\n",
    "history = model_rnn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 74.01512136888182%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test_predicted = model_rnn.predict(X_test)\n",
    "y_test_predicted = np.where(y_test_predicted >= 0.5, 1, y_test_predicted)\n",
    "y_test_predicted = np.where(y_test_predicted < 0.5, 0, y_test_predicted)\n",
    "accuracy = accuracy_score(y_test, y_test_predicted)\n",
    "print('Accuracy is: '+ str(100*accuracy)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement tensorflow-gpu==1.5 (from versions: 1.13.1, 1.13.2, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0, 2.1.1, 2.1.2, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0)\n",
      "No matching distribution found for tensorflow-gpu==1.5\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --ignore-installed tensorflow-gpu==1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\jean_\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m   \u001b[1;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6579f534729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# go/tf-wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 83\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\jean_\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-6f51f63b44a2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-6f51f63b44a2>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    `pip install tensorflow\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "`pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (3.12.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (1.19.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jean_\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jean_\\anaconda3\\envs\\nlp_course\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pywrap_tensorflow' from 'tensorflow.python' (C:\\Users\\jean_\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d6579f534729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# go/tf-wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pywrap_tensorflow' from 'tensorflow.python' (C:\\Users\\jean_\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\jean_\\anaconda3\\lib\\site-packages (1.19.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
